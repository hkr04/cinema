{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.996005326231691,
  "eval_steps": 500,
  "global_step": 1125,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 0.30040138959884644,
      "learning_rate": 9.999512620046522e-05,
      "loss": 1.8236,
      "step": 5
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3825923800468445,
      "learning_rate": 9.998050575201771e-05,
      "loss": 1.6432,
      "step": 10
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.31000950932502747,
      "learning_rate": 9.995614150494293e-05,
      "loss": 1.6855,
      "step": 15
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3956393897533417,
      "learning_rate": 9.992203820909906e-05,
      "loss": 1.5878,
      "step": 20
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.278890460729599,
      "learning_rate": 9.987820251299122e-05,
      "loss": 1.5158,
      "step": 25
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3495313227176666,
      "learning_rate": 9.982464296247522e-05,
      "loss": 1.4083,
      "step": 30
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3683728277683258,
      "learning_rate": 9.976136999909156e-05,
      "loss": 1.3774,
      "step": 35
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.38670051097869873,
      "learning_rate": 9.968839595802982e-05,
      "loss": 1.4127,
      "step": 40
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2654349207878113,
      "learning_rate": 9.96057350657239e-05,
      "loss": 1.3596,
      "step": 45
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4051054120063782,
      "learning_rate": 9.951340343707852e-05,
      "loss": 1.4153,
      "step": 50
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3004169464111328,
      "learning_rate": 9.941141907232765e-05,
      "loss": 1.3066,
      "step": 55
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.42210307717323303,
      "learning_rate": 9.929980185352526e-05,
      "loss": 1.3783,
      "step": 60
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.30786654353141785,
      "learning_rate": 9.917857354066931e-05,
      "loss": 1.2977,
      "step": 65
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3378395736217499,
      "learning_rate": 9.904775776745958e-05,
      "loss": 1.2158,
      "step": 70
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.39933067560195923,
      "learning_rate": 9.890738003669029e-05,
      "loss": 1.3409,
      "step": 75
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3952407240867615,
      "learning_rate": 9.875746771527816e-05,
      "loss": 1.2305,
      "step": 80
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3338555693626404,
      "learning_rate": 9.859805002892732e-05,
      "loss": 1.2777,
      "step": 85
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3601211905479431,
      "learning_rate": 9.842915805643155e-05,
      "loss": 1.2311,
      "step": 90
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4257979393005371,
      "learning_rate": 9.825082472361557e-05,
      "loss": 1.2665,
      "step": 95
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4209441840648651,
      "learning_rate": 9.806308479691595e-05,
      "loss": 1.416,
      "step": 100
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.33752357959747314,
      "learning_rate": 9.786597487660337e-05,
      "loss": 1.2587,
      "step": 105
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4217284321784973,
      "learning_rate": 9.765953338964735e-05,
      "loss": 1.2533,
      "step": 110
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.32700204849243164,
      "learning_rate": 9.744380058222483e-05,
      "loss": 1.3293,
      "step": 115
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4128023684024811,
      "learning_rate": 9.721881851187406e-05,
      "loss": 1.4175,
      "step": 120
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.44871237874031067,
      "learning_rate": 9.698463103929542e-05,
      "loss": 1.2266,
      "step": 125
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.35277649760246277,
      "learning_rate": 9.674128381980072e-05,
      "loss": 1.2824,
      "step": 130
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.40705209970474243,
      "learning_rate": 9.648882429441257e-05,
      "loss": 1.3297,
      "step": 135
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4758085310459137,
      "learning_rate": 9.622730168061567e-05,
      "loss": 1.4074,
      "step": 140
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3919966220855713,
      "learning_rate": 9.595676696276172e-05,
      "loss": 1.3054,
      "step": 145
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.42879635095596313,
      "learning_rate": 9.567727288213005e-05,
      "loss": 1.1742,
      "step": 150
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3871366083621979,
      "learning_rate": 9.538887392664544e-05,
      "loss": 1.2589,
      "step": 155
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4479021728038788,
      "learning_rate": 9.50916263202557e-05,
      "loss": 1.4164,
      "step": 160
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.41842421889305115,
      "learning_rate": 9.478558801197065e-05,
      "loss": 1.3265,
      "step": 165
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.34780579805374146,
      "learning_rate": 9.447081866456489e-05,
      "loss": 1.2864,
      "step": 170
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.366592675447464,
      "learning_rate": 9.414737964294636e-05,
      "loss": 1.1971,
      "step": 175
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4589574337005615,
      "learning_rate": 9.381533400219318e-05,
      "loss": 1.3345,
      "step": 180
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.36797618865966797,
      "learning_rate": 9.347474647526095e-05,
      "loss": 1.3131,
      "step": 185
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.42391595244407654,
      "learning_rate": 9.312568346036288e-05,
      "loss": 1.1818,
      "step": 190
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.42560917139053345,
      "learning_rate": 9.276821300802534e-05,
      "loss": 1.2243,
      "step": 195
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4943532943725586,
      "learning_rate": 9.24024048078213e-05,
      "loss": 1.3346,
      "step": 200
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.43731212615966797,
      "learning_rate": 9.202833017478422e-05,
      "loss": 1.1357,
      "step": 205
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.4800627529621124,
      "learning_rate": 9.164606203550497e-05,
      "loss": 1.325,
      "step": 210
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.4762137532234192,
      "learning_rate": 9.125567491391476e-05,
      "loss": 1.1826,
      "step": 215
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.48504748940467834,
      "learning_rate": 9.085724491675642e-05,
      "loss": 1.2601,
      "step": 220
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5062132477760315,
      "learning_rate": 9.045084971874738e-05,
      "loss": 1.1435,
      "step": 225
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.4460507929325104,
      "learning_rate": 9.003656854743667e-05,
      "loss": 1.2779,
      "step": 230
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.4748776853084564,
      "learning_rate": 8.961448216775954e-05,
      "loss": 1.235,
      "step": 235
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.42729687690734863,
      "learning_rate": 8.9184672866292e-05,
      "loss": 1.3249,
      "step": 240
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.46275538206100464,
      "learning_rate": 8.874722443520899e-05,
      "loss": 1.204,
      "step": 245
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.4977428615093231,
      "learning_rate": 8.83022221559489e-05,
      "loss": 1.1054,
      "step": 250
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.4377272129058838,
      "learning_rate": 8.784975278258783e-05,
      "loss": 1.3189,
      "step": 255
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5242345333099365,
      "learning_rate": 8.73899045249266e-05,
      "loss": 1.2485,
      "step": 260
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.49142131209373474,
      "learning_rate": 8.692276703129421e-05,
      "loss": 1.2493,
      "step": 265
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.4849567711353302,
      "learning_rate": 8.644843137107059e-05,
      "loss": 1.1718,
      "step": 270
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5551666021347046,
      "learning_rate": 8.596699001693255e-05,
      "loss": 1.2634,
      "step": 275
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.620664119720459,
      "learning_rate": 8.547853682682604e-05,
      "loss": 1.2704,
      "step": 280
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.42635461688041687,
      "learning_rate": 8.498316702566828e-05,
      "loss": 1.1667,
      "step": 285
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.4889093339443207,
      "learning_rate": 8.44809771867835e-05,
      "loss": 1.1886,
      "step": 290
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.4826743006706238,
      "learning_rate": 8.397206521307584e-05,
      "loss": 1.2256,
      "step": 295
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5461626052856445,
      "learning_rate": 8.345653031794292e-05,
      "loss": 1.2547,
      "step": 300
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.5990776419639587,
      "learning_rate": 8.293447300593402e-05,
      "loss": 1.1581,
      "step": 305
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.627990186214447,
      "learning_rate": 8.240599505315655e-05,
      "loss": 1.2172,
      "step": 310
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5001443028450012,
      "learning_rate": 8.18711994874345e-05,
      "loss": 1.2194,
      "step": 315
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5535451173782349,
      "learning_rate": 8.133019056822304e-05,
      "loss": 1.1615,
      "step": 320
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5445585250854492,
      "learning_rate": 8.07830737662829e-05,
      "loss": 1.1363,
      "step": 325
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5236496925354004,
      "learning_rate": 8.022995574311876e-05,
      "loss": 1.0124,
      "step": 330
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6057804822921753,
      "learning_rate": 7.967094433018508e-05,
      "loss": 1.2429,
      "step": 335
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.5248844027519226,
      "learning_rate": 7.910614850786448e-05,
      "loss": 1.1974,
      "step": 340
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6939286589622498,
      "learning_rate": 7.85356783842216e-05,
      "loss": 1.1095,
      "step": 345
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5488977432250977,
      "learning_rate": 7.795964517353735e-05,
      "loss": 1.2668,
      "step": 350
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.6525838375091553,
      "learning_rate": 7.737816117462752e-05,
      "loss": 1.1181,
      "step": 355
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.4946754276752472,
      "learning_rate": 7.679133974894983e-05,
      "loss": 1.2727,
      "step": 360
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5642982721328735,
      "learning_rate": 7.619929529850397e-05,
      "loss": 1.2301,
      "step": 365
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.9056358337402344,
      "learning_rate": 7.560214324352858e-05,
      "loss": 1.2433,
      "step": 370
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.45542484521865845,
      "learning_rate": 7.500000000000001e-05,
      "loss": 1.204,
      "step": 375
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.5081357359886169,
      "learning_rate": 7.439298295693665e-05,
      "loss": 1.2062,
      "step": 380
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.49312150478363037,
      "learning_rate": 7.378121045351378e-05,
      "loss": 1.1066,
      "step": 385
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.4708380103111267,
      "learning_rate": 7.316480175599309e-05,
      "loss": 1.0694,
      "step": 390
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.4714478850364685,
      "learning_rate": 7.254387703447154e-05,
      "loss": 1.1747,
      "step": 395
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.40744778513908386,
      "learning_rate": 7.191855733945387e-05,
      "loss": 1.1029,
      "step": 400
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.5169418454170227,
      "learning_rate": 7.128896457825364e-05,
      "loss": 1.1936,
      "step": 405
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.6148422360420227,
      "learning_rate": 7.06552214912271e-05,
      "loss": 0.9981,
      "step": 410
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.6677167415618896,
      "learning_rate": 7.001745162784477e-05,
      "loss": 1.1719,
      "step": 415
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.5094283223152161,
      "learning_rate": 6.937577932260515e-05,
      "loss": 0.993,
      "step": 420
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.6442318558692932,
      "learning_rate": 6.873032967079561e-05,
      "loss": 1.0899,
      "step": 425
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.5115083456039429,
      "learning_rate": 6.808122850410461e-05,
      "loss": 1.1614,
      "step": 430
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.5829440951347351,
      "learning_rate": 6.742860236609077e-05,
      "loss": 1.1521,
      "step": 435
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.673841118812561,
      "learning_rate": 6.677257848751277e-05,
      "loss": 1.0519,
      "step": 440
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.484565407037735,
      "learning_rate": 6.611328476152557e-05,
      "loss": 1.0777,
      "step": 445
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.5579208135604858,
      "learning_rate": 6.545084971874738e-05,
      "loss": 1.1166,
      "step": 450
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.7024022340774536,
      "learning_rate": 6.478540250220234e-05,
      "loss": 1.0107,
      "step": 455
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.5017110705375671,
      "learning_rate": 6.411707284214384e-05,
      "loss": 1.2339,
      "step": 460
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.6745755672454834,
      "learning_rate": 6.344599103076329e-05,
      "loss": 1.268,
      "step": 465
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.6575321555137634,
      "learning_rate": 6.277228789678953e-05,
      "loss": 1.1055,
      "step": 470
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.9978212714195251,
      "learning_rate": 6.209609477998338e-05,
      "loss": 1.1932,
      "step": 475
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.6126421689987183,
      "learning_rate": 6.141754350553279e-05,
      "loss": 1.068,
      "step": 480
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.7229852676391602,
      "learning_rate": 6.073676635835317e-05,
      "loss": 1.0219,
      "step": 485
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.6124900579452515,
      "learning_rate": 6.005389605729824e-05,
      "loss": 1.0522,
      "step": 490
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.6418768763542175,
      "learning_rate": 5.9369065729286245e-05,
      "loss": 1.02,
      "step": 495
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.5202738046646118,
      "learning_rate": 5.868240888334653e-05,
      "loss": 1.1073,
      "step": 500
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.5450568199157715,
      "learning_rate": 5.799405938459175e-05,
      "loss": 1.0445,
      "step": 505
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.45761677622795105,
      "learning_rate": 5.730415142812059e-05,
      "loss": 1.065,
      "step": 510
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.610398530960083,
      "learning_rate": 5.661281951285613e-05,
      "loss": 1.0148,
      "step": 515
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.6057705283164978,
      "learning_rate": 5.5920198415325064e-05,
      "loss": 1.2092,
      "step": 520
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.5320348739624023,
      "learning_rate": 5.522642316338268e-05,
      "loss": 1.2383,
      "step": 525
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.6502677202224731,
      "learning_rate": 5.453162900988902e-05,
      "loss": 1.1716,
      "step": 530
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.5361301302909851,
      "learning_rate": 5.383595140634093e-05,
      "loss": 1.0979,
      "step": 535
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.6022111773490906,
      "learning_rate": 5.313952597646568e-05,
      "loss": 1.1174,
      "step": 540
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.6988235116004944,
      "learning_rate": 5.244248848978067e-05,
      "loss": 1.1298,
      "step": 545
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.5621591210365295,
      "learning_rate": 5.174497483512506e-05,
      "loss": 1.0472,
      "step": 550
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.7884616851806641,
      "learning_rate": 5.104712099416785e-05,
      "loss": 1.0081,
      "step": 555
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.6243852972984314,
      "learning_rate": 5.034906301489808e-05,
      "loss": 1.0664,
      "step": 560
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.6169993877410889,
      "learning_rate": 4.965093698510193e-05,
      "loss": 1.1465,
      "step": 565
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.6397836804389954,
      "learning_rate": 4.895287900583216e-05,
      "loss": 1.0444,
      "step": 570
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.6001793742179871,
      "learning_rate": 4.825502516487497e-05,
      "loss": 1.019,
      "step": 575
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.6340292692184448,
      "learning_rate": 4.755751151021934e-05,
      "loss": 1.2986,
      "step": 580
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.5864453315734863,
      "learning_rate": 4.6860474023534335e-05,
      "loss": 1.1014,
      "step": 585
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.651454508304596,
      "learning_rate": 4.616404859365907e-05,
      "loss": 1.1273,
      "step": 590
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.7042168974876404,
      "learning_rate": 4.5468370990111006e-05,
      "loss": 1.049,
      "step": 595
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.6851935386657715,
      "learning_rate": 4.477357683661734e-05,
      "loss": 0.9326,
      "step": 600
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.6418243050575256,
      "learning_rate": 4.407980158467495e-05,
      "loss": 0.9725,
      "step": 605
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.6410585045814514,
      "learning_rate": 4.3387180487143876e-05,
      "loss": 1.1456,
      "step": 610
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.7279824018478394,
      "learning_rate": 4.269584857187943e-05,
      "loss": 1.0204,
      "step": 615
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.6078852415084839,
      "learning_rate": 4.2005940615408264e-05,
      "loss": 1.1627,
      "step": 620
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.5824559926986694,
      "learning_rate": 4.131759111665349e-05,
      "loss": 1.0659,
      "step": 625
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.5362696051597595,
      "learning_rate": 4.063093427071376e-05,
      "loss": 0.9847,
      "step": 630
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.6523104906082153,
      "learning_rate": 3.9946103942701777e-05,
      "loss": 1.0037,
      "step": 635
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.6709939241409302,
      "learning_rate": 3.926323364164684e-05,
      "loss": 1.1233,
      "step": 640
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.5102510452270508,
      "learning_rate": 3.858245649446721e-05,
      "loss": 1.0324,
      "step": 645
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.592454195022583,
      "learning_rate": 3.790390522001662e-05,
      "loss": 1.0209,
      "step": 650
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.7193688750267029,
      "learning_rate": 3.7227712103210486e-05,
      "loss": 0.9559,
      "step": 655
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.5615062713623047,
      "learning_rate": 3.655400896923672e-05,
      "loss": 1.0206,
      "step": 660
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.7027919888496399,
      "learning_rate": 3.588292715785617e-05,
      "loss": 1.1567,
      "step": 665
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.6050662994384766,
      "learning_rate": 3.5214597497797684e-05,
      "loss": 1.0637,
      "step": 670
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.631515383720398,
      "learning_rate": 3.4549150281252636e-05,
      "loss": 1.0566,
      "step": 675
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.6312503814697266,
      "learning_rate": 3.388671523847445e-05,
      "loss": 1.0606,
      "step": 680
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.6628090143203735,
      "learning_rate": 3.322742151248725e-05,
      "loss": 1.0718,
      "step": 685
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.6231287121772766,
      "learning_rate": 3.257139763390925e-05,
      "loss": 1.1981,
      "step": 690
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.6352670788764954,
      "learning_rate": 3.1918771495895396e-05,
      "loss": 1.089,
      "step": 695
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.7724134922027588,
      "learning_rate": 3.12696703292044e-05,
      "loss": 1.0564,
      "step": 700
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.735499382019043,
      "learning_rate": 3.062422067739485e-05,
      "loss": 1.0234,
      "step": 705
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.57827228307724,
      "learning_rate": 2.9982548372155263e-05,
      "loss": 1.1673,
      "step": 710
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.6006031036376953,
      "learning_rate": 2.934477850877292e-05,
      "loss": 1.0082,
      "step": 715
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.5817115902900696,
      "learning_rate": 2.8711035421746367e-05,
      "loss": 1.1736,
      "step": 720
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.6588096618652344,
      "learning_rate": 2.8081442660546125e-05,
      "loss": 1.2478,
      "step": 725
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.5947713255882263,
      "learning_rate": 2.7456122965528475e-05,
      "loss": 0.9741,
      "step": 730
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.734473466873169,
      "learning_rate": 2.6835198244006927e-05,
      "loss": 1.0428,
      "step": 735
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.7360958456993103,
      "learning_rate": 2.6218789546486234e-05,
      "loss": 1.1352,
      "step": 740
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.5803751945495605,
      "learning_rate": 2.560701704306336e-05,
      "loss": 1.1687,
      "step": 745
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.6111403703689575,
      "learning_rate": 2.500000000000001e-05,
      "loss": 1.1821,
      "step": 750
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.544805645942688,
      "learning_rate": 2.4397856756471432e-05,
      "loss": 1.1029,
      "step": 755
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.8780903816223145,
      "learning_rate": 2.3800704701496053e-05,
      "loss": 0.9864,
      "step": 760
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.7074529528617859,
      "learning_rate": 2.3208660251050158e-05,
      "loss": 1.0001,
      "step": 765
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.6794402003288269,
      "learning_rate": 2.2621838825372493e-05,
      "loss": 0.9502,
      "step": 770
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.8815369009971619,
      "learning_rate": 2.2040354826462668e-05,
      "loss": 0.9782,
      "step": 775
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.5784610509872437,
      "learning_rate": 2.1464321615778422e-05,
      "loss": 0.9449,
      "step": 780
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.8320007920265198,
      "learning_rate": 2.0893851492135537e-05,
      "loss": 1.0659,
      "step": 785
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.609417736530304,
      "learning_rate": 2.0329055669814934e-05,
      "loss": 1.0936,
      "step": 790
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.6067203879356384,
      "learning_rate": 1.977004425688126e-05,
      "loss": 1.1921,
      "step": 795
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.49981874227523804,
      "learning_rate": 1.9216926233717085e-05,
      "loss": 0.8247,
      "step": 800
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.6414180994033813,
      "learning_rate": 1.866980943177699e-05,
      "loss": 1.1265,
      "step": 805
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.5475558042526245,
      "learning_rate": 1.8128800512565513e-05,
      "loss": 1.0534,
      "step": 810
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.6145918965339661,
      "learning_rate": 1.7594004946843456e-05,
      "loss": 1.1272,
      "step": 815
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.6411255598068237,
      "learning_rate": 1.7065526994065973e-05,
      "loss": 1.0575,
      "step": 820
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.7213020324707031,
      "learning_rate": 1.6543469682057106e-05,
      "loss": 0.8845,
      "step": 825
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.726523220539093,
      "learning_rate": 1.602793478692419e-05,
      "loss": 1.1346,
      "step": 830
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.7048658728599548,
      "learning_rate": 1.551902281321651e-05,
      "loss": 1.036,
      "step": 835
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.6039611101150513,
      "learning_rate": 1.5016832974331724e-05,
      "loss": 1.1563,
      "step": 840
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.6868183612823486,
      "learning_rate": 1.4521463173173965e-05,
      "loss": 0.969,
      "step": 845
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.5806601047515869,
      "learning_rate": 1.4033009983067452e-05,
      "loss": 0.9754,
      "step": 850
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.6148064136505127,
      "learning_rate": 1.3551568628929434e-05,
      "loss": 1.0589,
      "step": 855
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.5474448204040527,
      "learning_rate": 1.3077232968705805e-05,
      "loss": 0.9132,
      "step": 860
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.5936747789382935,
      "learning_rate": 1.2610095475073414e-05,
      "loss": 0.9147,
      "step": 865
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.6488885283470154,
      "learning_rate": 1.2150247217412186e-05,
      "loss": 0.9639,
      "step": 870
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.7347344756126404,
      "learning_rate": 1.1697777844051105e-05,
      "loss": 0.8771,
      "step": 875
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.6163939237594604,
      "learning_rate": 1.1252775564791024e-05,
      "loss": 0.9241,
      "step": 880
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.7348925471305847,
      "learning_rate": 1.0815327133708015e-05,
      "loss": 0.9301,
      "step": 885
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.6319879293441772,
      "learning_rate": 1.0385517832240471e-05,
      "loss": 1.0591,
      "step": 890
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.6001115441322327,
      "learning_rate": 9.963431452563332e-06,
      "loss": 1.007,
      "step": 895
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.6000858545303345,
      "learning_rate": 9.549150281252633e-06,
      "loss": 1.0735,
      "step": 900
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.6941062211990356,
      "learning_rate": 9.142755083243576e-06,
      "loss": 0.9767,
      "step": 905
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.5630114078521729,
      "learning_rate": 8.744325086085248e-06,
      "loss": 0.9453,
      "step": 910
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.7831437587738037,
      "learning_rate": 8.353937964495029e-06,
      "loss": 0.8975,
      "step": 915
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.6324165463447571,
      "learning_rate": 7.971669825215788e-06,
      "loss": 1.0328,
      "step": 920
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.6548020243644714,
      "learning_rate": 7.597595192178702e-06,
      "loss": 1.0093,
      "step": 925
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.5688178539276123,
      "learning_rate": 7.2317869919746705e-06,
      "loss": 1.0396,
      "step": 930
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.5141518712043762,
      "learning_rate": 6.874316539637127e-06,
      "loss": 0.9852,
      "step": 935
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.6086298823356628,
      "learning_rate": 6.52525352473905e-06,
      "loss": 1.1051,
      "step": 940
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.6604920625686646,
      "learning_rate": 6.184665997806832e-06,
      "loss": 1.0325,
      "step": 945
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.6773346066474915,
      "learning_rate": 5.852620357053651e-06,
      "loss": 1.0578,
      "step": 950
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.5696538090705872,
      "learning_rate": 5.529181335435124e-06,
      "loss": 1.0055,
      "step": 955
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.573937714099884,
      "learning_rate": 5.214411988029355e-06,
      "loss": 0.9569,
      "step": 960
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.7125385403633118,
      "learning_rate": 4.908373679744316e-06,
      "loss": 1.1595,
      "step": 965
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.6258756518363953,
      "learning_rate": 4.611126073354571e-06,
      "loss": 0.9811,
      "step": 970
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.5769258141517639,
      "learning_rate": 4.322727117869951e-06,
      "loss": 1.0571,
      "step": 975
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.6745248436927795,
      "learning_rate": 4.043233037238281e-06,
      "loss": 1.0633,
      "step": 980
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.66926509141922,
      "learning_rate": 3.772698319384349e-06,
      "loss": 1.0873,
      "step": 985
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.5492319464683533,
      "learning_rate": 3.511175705587433e-06,
      "loss": 1.067,
      "step": 990
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.6709501147270203,
      "learning_rate": 3.258716180199278e-06,
      "loss": 1.2275,
      "step": 995
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.7975574731826782,
      "learning_rate": 3.0153689607045845e-06,
      "loss": 1.0609,
      "step": 1000
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.7496240735054016,
      "learning_rate": 2.7811814881259503e-06,
      "loss": 0.9568,
      "step": 1005
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.6759869456291199,
      "learning_rate": 2.5561994177751737e-06,
      "loss": 1.0403,
      "step": 1010
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.8073573708534241,
      "learning_rate": 2.340466610352654e-06,
      "loss": 1.0317,
      "step": 1015
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.6783883571624756,
      "learning_rate": 2.134025123396638e-06,
      "loss": 0.969,
      "step": 1020
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.6769505143165588,
      "learning_rate": 1.9369152030840556e-06,
      "loss": 0.9972,
      "step": 1025
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.6717817187309265,
      "learning_rate": 1.7491752763844293e-06,
      "loss": 1.0463,
      "step": 1030
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.7861670255661011,
      "learning_rate": 1.5708419435684462e-06,
      "loss": 0.9974,
      "step": 1035
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.7070798873901367,
      "learning_rate": 1.4019499710726913e-06,
      "loss": 1.0841,
      "step": 1040
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.5859964489936829,
      "learning_rate": 1.2425322847218368e-06,
      "loss": 1.1211,
      "step": 1045
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.5766963362693787,
      "learning_rate": 1.0926199633097157e-06,
      "loss": 1.0602,
      "step": 1050
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.581488847732544,
      "learning_rate": 9.522422325404235e-07,
      "loss": 1.0315,
      "step": 1055
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.7153448462486267,
      "learning_rate": 8.214264593307098e-07,
      "loss": 1.0543,
      "step": 1060
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.6131662130355835,
      "learning_rate": 7.001981464747565e-07,
      "loss": 0.997,
      "step": 1065
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.6122936606407166,
      "learning_rate": 5.885809276723608e-07,
      "loss": 0.9962,
      "step": 1070
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.6376161575317383,
      "learning_rate": 4.865965629214819e-07,
      "loss": 1.0552,
      "step": 1075
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.5981242060661316,
      "learning_rate": 3.9426493427611177e-07,
      "loss": 1.1288,
      "step": 1080
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.7757564187049866,
      "learning_rate": 3.1160404197018154e-07,
      "loss": 1.0283,
      "step": 1085
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.6224473118782043,
      "learning_rate": 2.386300009084408e-07,
      "loss": 1.0384,
      "step": 1090
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.6717422008514404,
      "learning_rate": 1.753570375247815e-07,
      "loss": 1.0089,
      "step": 1095
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.8711951971054077,
      "learning_rate": 1.2179748700879012e-07,
      "loss": 1.005,
      "step": 1100
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.6424548625946045,
      "learning_rate": 7.796179090094891e-08,
      "loss": 1.0418,
      "step": 1105
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.5768123865127563,
      "learning_rate": 4.385849505708084e-08,
      "loss": 1.0885,
      "step": 1110
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.8078117370605469,
      "learning_rate": 1.949424798228239e-08,
      "loss": 1.0388,
      "step": 1115
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.5952708125114441,
      "learning_rate": 4.873799534788059e-09,
      "loss": 0.9789,
      "step": 1120
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.5789183378219604,
      "learning_rate": 0.0,
      "loss": 0.9686,
      "step": 1125
    },
    {
      "epoch": 3.0,
      "step": 1125,
      "total_flos": 9.264571503280128e+16,
      "train_loss": 1.134859889984131,
      "train_runtime": 1975.9454,
      "train_samples_per_second": 4.558,
      "train_steps_per_second": 0.569
    }
  ],
  "logging_steps": 5,
  "max_steps": 1125,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "total_flos": 9.264571503280128e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
